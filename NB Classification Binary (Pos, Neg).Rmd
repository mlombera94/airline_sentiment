---
title: "Positive/Negative Naive Bayes Classification"
output: rmarkdown::github_document

---
#Load Library
```{r, results= "hide"}
library(readr)
library(tm)
library(SnowballC)
library(wordcloud)
library(e1071)
library(gmodels)
library(ggplot2)
library(caret)
library(ROCR)
library(dplyr)
```
#
#
#Step 1: Load the data
```{r}
tweets <- read_csv("Tweets.csv")
tweets %>% head(10)
```
#
#
#Binary Classification (Filter out nuetral sentiment)
```{r}
tweets %>% subset(airline_sentiment %in% c("positive", "negative")) -> tweets
tweets$airline_sentiment %>% table()
```
#
#
####Check proportions of negative and positive
```{r}
#convert to factor before using table
tweets$airline_sentiment %>% as.factor() -> tweets$airline_sentiment
tweets$airline %>% as.factor() -> tweets$airline

#sum of each category of tweet
tweets$airline_sentiment %>% table()

#sum of total tweets each airline has
tweets$airline %>% table()
```
#
```{r}
#Pie chart comparing the ratio of negative and positive tweets
tweets %>% ggplot(aes(x= factor(1), fill= airline_sentiment)) + 
  geom_bar(width = 1) + coord_polar(theta="y") + 
  ggtitle("Ratio of classified tweets")

#Pie chart comparing the ratio of tweets per airline
tweets %>% ggplot(aes(x= factor(1), fill= airline)) + 
  geom_bar(width = 1) + coord_polar(theta="y") + 
  ggtitle("Ratio of total tweets per Airline")

#Plot proportion table of airlines with their airline sentiment
tweets %>% ggplot(aes(x = airline, fill = airline_sentiment)) + 
  geom_bar(position = "fill") + 
  ggtitle("Proportion of classified tweets per Airline")

#Plot the frequency of the three different types of tweets each airline receives
tweets %>% ggplot(aes(x = airline, fill = airline_sentiment)) + 
  geom_bar() + 
  ggtitle("Frequency of each classified tweet per Airline")
```
#
#
####Begin preparing the text data
```{r}
#Get rid of special characters
tweets$text <- gsub("[^[:alnum:][:blank:]?&/\\-]", "", tweets$text)

#Looks at tweets 
tweets$text[1:5]

#remove @airline name as it is not neccessary
stopwords = c("American", "Delta", "Southwest", "United", "US Airways", "VirginAmerica", "SouthwestAirlines", "AmericanAirlines" )
tweets$text %>% removeWords(stopwords) -> tweets$text

#check to make sure words were removed 
tweets$text[1:5]

#create corpus and examine it 
tweets$text %>% VectorSource() %>% VCorpus() -> tweet_corpus

tweet_corpus[1:5] %>% lapply(as.character)
```
#
#
####Clean up Corpus
```{r}
#Convert text to lowercase, remove numbers, stopwords, and punctuation 
tweet_corpus %>% tm_map(content_transformer(tolower)) %>% 
  tm_map(removeNumbers) %>% 
  tm_map(removeWords, stopwords('english')) %>% 
  tm_map(removePunctuation) -> tweet_corpus_clean

#Check to see if clean
lapply(tweet_corpus_clean[1:5], as.character)
```
#
#
####Wordstem and check final clean corpus 
```{r}
#wordstem and strip whitespace 
tweet_corpus_clean %>%  tm_map(stemDocument) %>% 
  tm_map(stripWhitespace) -> tweet_corpus_clean
  
#remove other common words that dont help with sentiment
stopwords2 <- c("southwestair", "americanair", "jetblu", "usairway", "unit", "newark", "houston", "airport", "lax", "jfk", "what", "your", "that", "one", "week", "two", "tonight", "tomorrow", "year", "dfw", "night")
tweet_corpus_clean %>% tm_map(removeWords, stopwords2) -> tweet_corpus_clean

#create dataframe
tweet_corpus_clean %>% DocumentTermMatrix() -> tweet_dtm

#Check final text 
tweet_corpus_clean[1:5] %>% lapply(as.character)
tweet_dtm
```
#
#
####Create training and test dataframe and lables
```{r}
#create random sample
set.seed(123)
idx <- sample(seq(1, 3), size = nrow(tweet_dtm), replace = TRUE, prob = c(.8, .2, .2 ))

#training, test, and validation
tweet_dtm_train <- tweet_dtm[idx == 1, ]
tweet_dtm_test <- tweet_dtm[idx == 2,]
tweet_dtm_validation <- tweet_dtm[idx == 3,]

#labels 
tweet_train_labels <- tweets[idx == 1, ]$airline_sentiment
tweet_test_labels <- tweets[idx == 2, ]$airline_sentiment
tweet_validation_labels <- tweets[idx == 3, ]$airline_sentiment

#check that proportions are similar
tweet_train_labels %>% table() %>% prop.table()
tweet_test_labels %>% table() %>% prop.table()
tweet_validation_labels %>% table() %>% prop.table()
```
#
#
####Word Cloud visualization
```{r}
tweet_corpus_clean %>% wordcloud(max.words = 150, min.freq = 10, random.order = F)
```
#
#
####Subset the data to visualize common words for each sentiment
```{r}
tweets %>% subset(airline_sentiment== "positive") -> positive
tweets %>% subset(airline_sentiment== "negative") -> negative
```
#
#
```{r}
positive$text %>% wordcloud(max.words = 100, scale = c(3, .5))
negative$text %>% wordcloud(max.words = 100, scale = c(3, .5))
```
#
#
#Step 3: Training a model on the data
```{r, results= "hide"}
tweet_dtm_train %>% removeSparseTerms(0.999) -> tweet_dtm_freq_train
tweet_dtm_freq_train

tweet_dtm_train %>% findFreqTerms(10) -> tweet_freq_words
str(tweet_freq_words)
```
#
#
####Create DTMs with only the frequent terms
```{r, results= "hide"}
tweet_dtm_freq_train <- tweet_dtm_train[ , tweet_freq_words]
tweet_dtm_freq_validation <- tweet_dtm_validation[ , tweet_freq_words]
tweet_dtm_freq_test <- tweet_dtm_test[ , tweet_freq_words]
```
#
#
####Create a function to convert counts to a factor and apply it to columns of train/test data and begin training a model on the data
```{r}
convert_counts <- function(x) {
  x <- ifelse(x > 0, "Yes", "No")
}

tweet_dtm_freq_train %>% apply(MARGIN = 2, convert_counts) -> tweet_train
tweet_dtm_freq_validation %>% apply(MARGIN = 2, convert_counts) -> tweet_validation 
tweet_dtm_freq_test %>% apply(MARGIN = 2, convert_counts) -> tweet_test

tweet_train %>% naiveBayes(tweet_train_labels) -> tweet_classifier
```
#
#
#Step 4: Evaluate the model's performance
```{r}
tweet_classifier %>% predict(tweet_validation) -> tweet_validation_pred

tweet_validation_pred %>% head(n = 15)

tweet_validation_pred %>% confusionMatrix(tweet_validation_labels) -> conf

conf

confusion_matrix <- as.data.frame(table(tweet_validation_pred, tweet_validation_labels))

confusion_matrix %>% ggplot(aes(x = tweet_validation_pred, y = tweet_validation_labels)) + 
  geom_tile(aes(fill = Freq)) +
  geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
  scale_fill_gradient(low = "#ff7f50",
                      high = "#003767",
                      trans = "log")
```
####89.12% classified accurately
#
#
#Step 5: Improve the model
```{r}
tweet_train %>% naiveBayes(tweet_train_labels, laplace = 1) -> tweet_classifier2

tweet_classifier2 %>% predict(tweet_validation) -> tweet_validation_pred2

tweet_validation_pred2 %>% confusionMatrix(tweet_validation_labels) -> conf2

conf2

confusion_matrix2 <- as.data.frame(table(tweet_validation_pred2, tweet_validation_labels))

confusion_matrix2 %>% ggplot(aes(x = tweet_validation_pred2, y = tweet_validation_labels)) +
  geom_tile(aes(fill = Freq)) +
  geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
  scale_fill_gradient(low = "#ff7f50",
                      high = "#003767",
                      trans = "log")
```
####89.79% classified accurately
#
#Final Test on test dataset
```{r}
tweet_classifier2 %>% predict(tweet_test) -> tweet_test_pred

tweet_test_pred %>% confusionMatrix(tweet_test_labels) -> conf3

conf3

confusion_matrix3 <- as.data.frame(table(tweet_test_pred, tweet_test_labels))

confusion_matrix3 %>% ggplot(aes(x = tweet_test_pred, y = tweet_test_labels)) +
  geom_tile(aes(fill = Freq)) +
  geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
  scale_fill_gradient(low = "#ff7f50",
                      high = "#003767",
                      trans = "log")
```
####91.61% classified correctly
